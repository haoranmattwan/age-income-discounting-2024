{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c85bf5",
   "metadata": {},
   "source": [
    "# Replication Analysis: Income Moderates Age-Related Financial Patience\n",
    "### A Python implementation of the findings from Wan et al. (2024), *Psychology and Aging*\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "\n",
    "This notebook provides a complete, reproducible Python workflow for the analyses presented in the following publication:\n",
    "\n",
    "> Wan, H., Myerson, J., Green, L., Strube, M. J., & Hale, S. (2024). Age-related differences in delay discounting: Income matters. *Psychology and Aging*. Advance online publication. https://doi.org/10.1037/pag0000818\n",
    "\n",
    "The original analysis was conducted in R, and this notebook serves to replicate the findings using the Python data science ecosystem. The project's goal is to test the **\"buffering hypothesis\"**—the theory posits that the greater emotional stability of older adults buffers them against the financial stress of scarcity, leading to more patient financial decisions compared to their younger, low-income counterparts.\n",
    "\n",
    "### Technical Workflow\n",
    "\n",
    "The analysis is structured in five sequential stages:\n",
    "\n",
    "1.  **Setup & Data Import**: Load required Python libraries (`pandas`, `statsmodels`, `pymc`, etc.) and the raw dataset.\n",
    "2.  **Data Processing & Validation**: Clean the data, create analysis-ready dataframes, and perform data quality and reliability checks.\n",
    "3.  **Hypothesis Testing 1 (Age Effects)**: Replicate the Bayesian multilevel models from Table 2 of the paper, testing the effect of age on financial patience within each income group.\n",
    "4.  **Hypothesis Testing 2 (Income Effects)**: Replicate the models from Table 3, testing the effect of income within each age group.\n",
    "5.  **Composite Score Analysis**: Create a composite z-score to perform final correlation tests and quantify the magnitude of the key interaction effect.\n",
    "\n",
    "The data and original study materials are publicly available on the Open Science Framework at [https://osf.io/um68t/](https://osf.io/um68t/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f0c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment Setup ---\n",
    "#\n",
    "# This cell installs the required Python packages for the analysis.\n",
    "# Uncomment and run this cell only if you are setting up a new environment.\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas numpy openpyxl scipy statsmodels pymc arviz scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d009214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SETUP: IMPORTS, FUNCTIONS, AND DATA PROCESSING ---\n",
    "\n",
    "# --- 1.1 Load Libraries ---\n",
    "\n",
    "# Core data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Statistical modeling and analysis\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Suppress warnings for a cleaner final report\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set pandas display options for consistent formatting\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "\n",
    "# --- 1.2 Custom Bayesian Modeling Functions ---\n",
    "\n",
    "def fit_bayesian_glmm(formula: str, data: pd.DataFrame, family: str = 'binomial', progressbar: bool = False):\n",
    "    \"\"\"\n",
    "    Fits a Bayesian Generalized Linear Mixed-Effects Model using PyMC.\n",
    "\n",
    "    This function is designed to replicate the brms models from the R analysis,\n",
    "    including a random intercept for participant ID.\n",
    "\n",
    "    Args:\n",
    "        formula (str): A statsmodels-style formula (e.g., \"outcome ~ predictor\").\n",
    "        data (pd.DataFrame): The dataframe containing the model variables.\n",
    "        family (str): The likelihood distribution ('binomial' or 'beta').\n",
    "        progressbar (bool): Whether to display the MCMC sampling progress bar.\n",
    "\n",
    "    Returns:\n",
    "        arviz.InferenceData: The fitted model object containing posterior samples.\n",
    "    \"\"\"\n",
    "    outcome, predictors = formula.split('~')\n",
    "    outcome = outcome.strip()\n",
    "    \n",
    "    # Use patsy to parse the formula and create design matrices\n",
    "    y, X = pd.factorize(data['ID'])\n",
    "    coords = {\"obs_id\": np.arange(data.shape[0]), \"participant\": X}\n",
    "    participant_idx = y\n",
    "\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # --- Priors ---\n",
    "        # Priors are chosen to be weakly informative, matching the R brms setup.\n",
    "        intercept = pm.Normal(\"Intercept\", mu=0, sigma=10)\n",
    "        # Assumes a single slope for simplicity in this helper function\n",
    "        slope = pm.Normal(predictors.strip(), mu=0, sigma=2.5) \n",
    "        # Random intercepts for each participant\n",
    "        sd_participant = pm.HalfCauchy(\"sd_participant\", beta=2.5)\n",
    "        z_participant = pm.Normal(\"z_participant\", mu=0, sigma=1, dims=\"participant\")\n",
    "        participant_effect = z_participant * sd_participant\n",
    "        \n",
    "        # --- Linear Model ---\n",
    "        eta = (intercept +  slope * data[predictors.strip()] + participant_effect[participant_idx])\n",
    "\n",
    "        # --- Likelihood ---\n",
    "        if family == 'binomial':\n",
    "            p = pm.math.invlogit(eta)\n",
    "            pm.Binomial(\n",
    "                outcome,\n",
    "                n=data['trials'].values,\n",
    "                p=p,\n",
    "                observed=data[outcome].values,\n",
    "                dims=\"obs_id\"\n",
    "            )\n",
    "        elif family == 'beta':\n",
    "            # For Beta regression, the precision parameter (nu) also needs a prior\n",
    "            nu = pm.HalfCauchy(\"nu\", beta=10) \n",
    "            mu = pm.math.invlogit(eta)\n",
    "            pm.Beta(\n",
    "                outcome,\n",
    "                mu=mu,\n",
    "                nu=nu, \n",
    "                observed=data[outcome].values,\n",
    "                dims=\"obs_id\"\n",
    "            )\n",
    "\n",
    "        # --- MCMC Sampling ---\n",
    "        idata = pm.sample(draws=2000, tune=2000, chains=4, cores=4, target_accept=0.95, progressbar=progressbar)\n",
    "    return idata\n",
    "\n",
    "def summarize_pymc_model(idata, var_names=None):\n",
    "    \"\"\"\n",
    "    Creates a clean summary table from a PyMC InferenceData object.\n",
    "\n",
    "    Args:\n",
    "        idata (arviz.InferenceData): A fitted PyMC model object.\n",
    "        var_names (list, optional): List of variable names to include in the summary.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A formatted summary table including mean, HDI, and pd.\n",
    "    \"\"\"\n",
    "    summary_df = az.summary(idata, hdi_prob=0.95, kind='stats', var_names=var_names)\n",
    "    \n",
    "    # Calculate Probability of Direction (pd)\n",
    "    posterior = az.extract(idata, var_names=var_names)\n",
    "    pd_values = {}\n",
    "    for var in posterior.data_vars:\n",
    "        samples = posterior[var].values.flatten()\n",
    "        pd_val = np.mean(samples > 0)\n",
    "        pd_val = max(pd_val, 1 - pd_val) # Ensure pd is always >= 0.5\n",
    "        pd_values[var] = pd_val\n",
    "        \n",
    "    summary_df['pd'] = summary_df.index.map(pd_values)\n",
    "    summary_df['significance'] = np.where(summary_df['pd'] >= 0.975, '*', ' ')\n",
    "    summary_df = summary_df[['mean', 'hdi_2.5%', 'hdi_97.5%', 'pd', 'significance']]\n",
    "    summary_df.columns = ['Median', 'CI_lower', 'CI_upper', 'pd', 'sig']\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "\n",
    "# --- 1.3 Load and Process Data ---\n",
    "\n",
    "# Load raw data from the two sheets in the Excel file\n",
    "raw_mcq_df = pd.read_excel(\"Data_AgeIncome.xlsx\", sheet_name=\"MCQ\")\n",
    "raw_adj_amt_df = pd.read_excel(\"Data_AgeIncome.xlsx\", sheet_name=\"Adj-Amt\")\n",
    "\n",
    "# Create a lookup table for MCQ item parameters - a much cleaner approach\n",
    "mcq_item_params = pd.DataFrame({\n",
    "    'Q_ID': range(1, 28),\n",
    "    'k': [0.00016, 0.006, 0.006, 0.25, 0.041, 0.0004, 0.1, 0.1, 0.00016, 0.006, \n",
    "          0.25, 0.001, 0.00016, 0.041, 0.0025, 0.0025, 0.0004, 0.016, 0.1, 0.0004, \n",
    "          0.016, 0.0025, 0.041, 0.001, 0.016, 0.001, 0.25],\n",
    "    'Amount': [\"$55\", \"$80\", \"$30\", \"$80\", \"$30\", \"$55\", \"$30\", \"$55\", \"$80\", \n",
    "               \"$55\", \"$30\", \"$80\", \"$30\", \"$55\", \"$80\", \"$55\", \"$80\", \"$30\", \n",
    "               \"$80\", \"$30\", \"$55\", \"$30\", \"$80\", \"$55\", \"$80\", \"$30\", \"$55\"]\n",
    "})\n",
    "\n",
    "# Merge the parameters with the raw MCQ data\n",
    "mcq_df_with_params = pd.merge(raw_mcq_df, mcq_item_params, on='Q_ID')\n",
    "mcq_df_with_params['Amount'] = pd.Categorical(\n",
    "    mcq_df_with_params['Amount'], \n",
    "    categories=[\"$80\", \"$55\", \"$30\"], ordered=True\n",
    ")\n",
    "\n",
    "# Calculate participant-level summaries for each behavioral task\n",
    "adj_amt_participant_summary = raw_adj_amt_df[raw_adj_amt_df['Delay'] != 730].groupby(['ID', 'Amount']).apply(\n",
    "    lambda g: pd.Series({'auc': np.trapz(g['RSV'], g['Delay'] / g['Delay'].max())})\n",
    ").reset_index()\n",
    "\n",
    "mcq_participant_summary = mcq_df_with_params.groupby(['ID', 'Amount'], observed=True).agg(\n",
    "    num_delayed_choices=('Choice', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Create master demographics dataframe and join to behavioral summaries\n",
    "demographics_df = raw_adj_amt_df[['ID', 'Group', 'Age', 'Gender', 'Education', 'HADS']].drop_duplicates()\n",
    "demographics_df['age_group'] = np.where(demographics_df['Group'].isin([1, 2]), 0, 1)    # 0=Younger\n",
    "demographics_df['income_group'] = np.where(demographics_df['Group'].isin([1, 3]), 0, 1) # 0=Lower\n",
    "demographics_df['education_group'] = np.where(demographics_df['Education'] <= 3, 0, 1)\n",
    "demographics_df['hads_score'] = pd.to_numeric(demographics_df['HADS'], errors='coerce')\n",
    "\n",
    "mcq_analysis_df = pd.merge(mcq_participant_summary, demographics_df, on='ID')\n",
    "adj_amt_analysis_df = pd.merge(adj_amt_participant_summary, demographics_df, on='ID')\n",
    "\n",
    "# Create model-specific dataframes with centered variables\n",
    "def add_centered_predictors(df, cols):\n",
    "    df_copy = df.copy()\n",
    "    for col in cols:\n",
    "        df_copy[f'{col}_c'] = df_copy[col] - df_copy[col].mean()\n",
    "    return df_copy\n",
    "\n",
    "mcq_model1_df = mcq_analysis_df[mcq_analysis_df['Amount'].isin([\"$30\", \"$80\"])]\n",
    "mcq_model1_df = add_centered_predictors(mcq_model1_df, ['age_group', 'income_group'])\n",
    "mcq_model1_df['trials'] = 9 # Number of choices per block\n",
    "\n",
    "adj_amt_model1_df = adj_amt_analysis_df[adj_amt_analysis_df['Amount'].isin([30, 80])]\n",
    "adj_amt_model1_df = add_centered_predictors(adj_amt_model1_df, ['age_group', 'income_group'])\n",
    "\n",
    "# Create the composite z-score dataframe\n",
    "mcq_z = mcq_analysis_df[mcq_analysis_df['Amount'].isin([\"$30\", \"$80\"])].sort_values(['ID', 'Amount'], ascending=[True, False])\n",
    "adj_z = adj_amt_analysis_df[adj_amt_analysis_df['Amount'].isin([30, 80])]\n",
    "composite_score_df = mcq_z[['ID', 'age_group', 'income_group', 'Age', 'num_delayed_choices']].copy()\n",
    "composite_score_df['auc'] = adj_z['auc'].values\n",
    "composite_score_df['mcq_z'] = (composite_score_df['num_delayed_choices'] - composite_score_df['num_delayed_choices'].mean()) / composite_score_df['num_delayed_choices'].std()\n",
    "composite_score_df['adj_amt_z'] = (composite_score_df['auc'] - composite_score_df['auc'].mean()) / composite_score_df['auc'].std()\n",
    "composite_score_df['mean_z_score'] = composite_score_df[['mcq_z', 'adj_amt_z']].mean(axis=1)\n",
    "composite_score_df = composite_score_df.groupby('ID').mean().reset_index() # Average z-score per participant\n",
    "composite_score_df = add_centered_predictors(composite_score_df, ['age_group', 'income_group'])\n",
    "composite_score_df['age_c'] = (composite_score_df['Age'] - composite_score_df['Age'].mean()) / composite_score_df['Age'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6cf4f1",
   "metadata": {},
   "source": [
    "## 2. Data Quality & Reliability Checks\n",
    "\n",
    "Before testing the primary hypotheses, this section replicates the initial analyses from the paper that establish the quality and internal consistency of the behavioral data. These checks confirm two key points:\n",
    "\n",
    "1.  **Validity Check**: We fit established mathematical models of choice behavior (a logistic growth function for MCQ data and a hyperboloid function for Adj-Amt data) to the group-level data. R-squared values indicate that participants' choices were systematic and not random, conforming to theoretical expectations.\n",
    "2.  **Reliability Check**: We assess the internal consistency of our measures by correlating participants' scores across the different reward amounts within each task. High positive correlations demonstrate that the tasks are reliable; for example, a participant who was impatient for a small reward was also likely to be impatient for a large one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908578b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1 Group-Level Model Fit Assessment ---\n",
    "\n",
    "# Import the specific functions required for this cell's analysis\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# The following analyses assess how well standard mathematical models of choice\n",
    "# describe the aggregated data from each of the four participant groups.\n",
    "# High R-squared values indicate that the data is well-behaved and systematic.\n",
    "\n",
    "# Define the mathematical functions for curve fitting\n",
    "def logistic_growth(log_k, a, r):\n",
    "    \"\"\"Logistic growth function used to model MCQ choice proportions.\"\"\"\n",
    "    return 1 / (1 + np.exp(-(log_k - a) * r))\n",
    "\n",
    "def hyperboloid(delay, k, s):\n",
    "    \"\"\"Hyperboloid function used to model delay discounting.\"\"\"\n",
    "    return 1 / (1 + k * delay)**s\n",
    "\n",
    "# --- Create aggregated dataframes for group-level analysis ---\n",
    "group_labels = {\n",
    "    1: \"Younger, Lower-Income\", 2: \"Younger, Higher-Income\",\n",
    "    3: \"Older, Lower-Income\", 4: \"Older, Higher-Income\"\n",
    "}\n",
    "mcq_df_with_params['group_label'] = mcq_df_with_params['Group'].map(group_labels)\n",
    "raw_adj_amt_df['group_label'] = raw_adj_amt_df['Group'].map(group_labels)\n",
    "\n",
    "mcq_group_summary = mcq_df_with_params.groupby(['group_label', 'Amount', 'k'], observed=True).agg(\n",
    "    prop_delayed=('Choice', 'mean')\n",
    ").reset_index()\n",
    "mcq_group_summary['log_k'] = np.log(mcq_group_summary['k'])\n",
    "\n",
    "adj_amt_group_summary = raw_adj_amt_df.groupby(['group_label', 'Amount', 'Delay']).agg(\n",
    "    mean_rsv=('RSV', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# --- Fit models and calculate R-squared ---\n",
    "print(\"--- MCQ: R-squared for Group-Level Logistic Growth Fits ---\")\n",
    "def calculate_r2(df, x_col, y_col, model_func, p0):\n",
    "    \"\"\"Helper function to fit a curve and return R-squared.\"\"\"\n",
    "    params, _ = curve_fit(model_func, df[x_col], df[y_col], p0=p0)\n",
    "    y_pred = model_func(df[x_col], *params)\n",
    "    return r2_score(df[y_col], y_pred)\n",
    "\n",
    "r2_mcq = mcq_group_summary.groupby(['group_label', 'Amount'], observed=True).apply(\n",
    "    calculate_r2, x_col='log_k', y_col='prop_delayed', model_func=logistic_growth, p0=[-4, 1]\n",
    ").unstack()\n",
    "print(r2_mcq)\n",
    "\n",
    "print(\"\\n--- Adj-Amt: R-squared for Group-Level Hyperboloid Fits ---\")\n",
    "r2_adj_amt = adj_amt_group_summary.groupby(['group_label', 'Amount']).apply(\n",
    "    calculate_r2, x_col='Delay', y_col='mean_rsv', model_func=hyperboloid, p0=[0.1, 1]\n",
    ").unstack()\n",
    "print(r2_adj_amt)\n",
    "\n",
    "\n",
    "# --- 2.2 Within-Procedure Reliability (Alternate-Forms Reliability) ---\n",
    "\n",
    "# These analyses check if participants' discounting rates are consistent across\n",
    "# different reward amounts within the same procedure.\n",
    "\n",
    "print(\"\\n\\n--- MCQ: Within-Procedure Correlations (Number of Delayed Choices) ---\")\n",
    "mcq_reliability_pivot = mcq_participant_summary.pivot(\n",
    "    index='ID', columns='Amount', values='num_delayed_choices'\n",
    ")\n",
    "print(mcq_reliability_pivot.corr())\n",
    "\n",
    "print(\"\\n--- Adj-Amt: Within-Procedure Correlations (AuC) ---\")\n",
    "adj_amt_reliability_pivot = adj_amt_participant_summary.pivot(\n",
    "    index='ID', columns='Amount', values='auc'\n",
    ")\n",
    "# Rename columns for clarity in the correlation matrix\n",
    "adj_amt_reliability_pivot.columns = [f\"${c}\" for c in adj_amt_reliability_pivot.columns]\n",
    "print(adj_amt_reliability_pivot.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d4c644",
   "metadata": {},
   "source": [
    "## 3. Hypothesis Testing: Effects of Age on Discounting\n",
    "\n",
    "This section replicates the core analyses from **Table 2** of the publication, which test the primary prediction of the **buffering hypothesis**. The key prediction is that **age will be associated with more patient decision-making (less discounting), but only for the low-income group**. No significant age effect is expected for the high-income group, as they are not experiencing the same level of financial scarcity.\n",
    "\n",
    "To test this, we fit a series of Bayesian generalized linear mixed-effects models separately for each income group. The models predict discounting behavior as a function of age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84573f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.1 Model 1: Baseline Effect of Age ---\n",
    "\n",
    "# This analysis tests the main prediction: is there an effect of age on discounting\n",
    "# for each income group, before controlling for other factors?\n",
    "\n",
    "# --- Low-Income Group Analysis ---\n",
    "print(\"--- MODEL 1: AGE EFFECTS (LOW-INCOME GROUP) ---\")\n",
    "# Subset the data for the low-income group\n",
    "low_income_mcq_df = mcq_model1_df[mcq_model1_df['income_group'] == 0]\n",
    "low_income_adj_amt_df = adj_amt_model1_df[adj_amt_model1_df['income_group'] == 0]\n",
    "\n",
    "# Fit Bayesian models\n",
    "idata_mcq_age_low_inc = fit_bayesian_glmm(\n",
    "    \"num_delayed_choices ~ age_group_c\",\n",
    "    low_income_mcq_df,\n",
    "    family='binomial'\n",
    ")\n",
    "idata_adj_amt_age_low_inc = fit_bayesian_glmm(\n",
    "    \"auc ~ age_group_c\",\n",
    "    low_income_adj_amt_df,\n",
    "    family='beta'\n",
    ")\n",
    "\n",
    "# Display summaries\n",
    "print(\"\\nMCQ Results (Low-Income):\")\n",
    "print(summarize_pymc_model(idata_mcq_age_low_inc, var_names=['Intercept', 'age_group_c']))\n",
    "print(\"\\nAdj-Amt Results (Low-Income):\")\n",
    "print(summarize_pymc_model(idata_adj_amt_age_low_inc, var_names=['Intercept', 'age_group_c']))\n",
    "\n",
    "\n",
    "# --- High-Income Group Analysis ---\n",
    "print(\"\\n\\n--- MODEL 1: AGE EFFECTS (HIGH-INCOME GROUP) ---\")\n",
    "# Subset the data for the high-income group\n",
    "high_income_mcq_df = mcq_model1_df[mcq_model1_df['income_group'] == 1]\n",
    "high_income_adj_amt_df = adj_amt_model1_df[adj_amt_model1_df['income_group'] == 1]\n",
    "\n",
    "# Fit Bayesian models\n",
    "idata_mcq_age_high_inc = fit_bayesian_glmm(\n",
    "    \"num_delayed_choices ~ age_group_c\",\n",
    "    high_income_mcq_df,\n",
    "    family='binomial'\n",
    ")\n",
    "idata_adj_amt_age_high_inc = fit_bayesian_glmm(\n",
    "    \"auc ~ age_group_c\",\n",
    "    high_income_adj_amt_df,\n",
    "    family='beta'\n",
    ")\n",
    "\n",
    "# Display summaries\n",
    "print(\"\\nMCQ Results (High-Income):\")\n",
    "print(summarize_pymc_model(idata_mcq_age_high_inc, var_names=['Intercept', 'age_group_c']))\n",
    "print(\"\\nAdj-Amt Results (High-Income):\")\n",
    "print(summarize_pymc_model(idata_adj_amt_age_high_inc, var_names=['Intercept', 'age_group_c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfefce",
   "metadata": {},
   "source": [
    "## 4. Hypothesis Testing: Effects of Income on Discounting\n",
    "\n",
    "This section replicates the complementary analyses from **Table 3** of the publication, providing a second test of the **buffering hypothesis**. The prediction here is the inverse of the previous section: **higher income will be associated with more patient decision-making, but only for the younger group**. Because older adults are already \"buffered\" by their greater emotional stability, their decision-making should be less influenced by income level.\n",
    "\n",
    "To test this, we fit a series of Bayesian generalized linear mixed-effects models separately for each age group to examine the effect of income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1 Model 1: Baseline Effect of Income ---\n",
    "\n",
    "# This analysis tests the complementary prediction: does higher income lead to\n",
    "# less discounting, and is this effect present only for younger adults?\n",
    "\n",
    "# --- Younger Adults Analysis ---\n",
    "print(\"--- MODEL 1: INCOME EFFECTS (YOUNGER ADULTS) ---\")\n",
    "# Subset the data for the younger group\n",
    "younger_mcq_df = mcq_model1_df[mcq_model1_df['age_group'] == 0]\n",
    "younger_adj_amt_df = adj_amt_model1_df[adj_amt_model1_df['age_group'] == 0]\n",
    "\n",
    "# Fit Bayesian models\n",
    "idata_mcq_income_younger = fit_bayesian_glmm(\n",
    "    \"num_delayed_choices ~ income_group_c\",\n",
    "    younger_mcq_df,\n",
    "    family='binomial'\n",
    ")\n",
    "idata_adj_amt_income_younger = fit_bayesian_glmm(\n",
    "    \"auc ~ income_group_c\",\n",
    "    younger_adj_amt_df,\n",
    "    family='beta'\n",
    ")\n",
    "\n",
    "# Display summaries\n",
    "print(\"\\nMCQ Results (Younger Adults):\")\n",
    "print(summarize_pymc_model(idata_mcq_income_younger, var_names=['Intercept', 'income_group_c']))\n",
    "print(\"\\nAdj-Amt Results (Younger Adults):\")\n",
    "print(summarize_pymc_model(idata_adj_amt_income_younger, var_names=['Intercept', 'income_group_c']))\n",
    "\n",
    "\n",
    "# --- Older Adults Analysis ---\n",
    "print(\"\\n\\n--- MODEL 1: INCOME EFFECTS (OLDER ADULTS) ---\")\n",
    "# Subset the data for the older group\n",
    "older_mcq_df = mcq_model1_df[mcq_model1_df['age_group'] == 1]\n",
    "older_adj_amt_df = adj_amt_model1_df[adj_amt_model1_df['age_group'] == 1]\n",
    "\n",
    "# Fit Bayesian models\n",
    "idata_mcq_income_older = fit_bayesian_glmm(\n",
    "    \"num_delayed_choices ~ income_group_c\",\n",
    "    older_mcq_df,\n",
    "    family='binomial'\n",
    ")\n",
    "idata_adj_amt_income_older = fit_bayesian_glmm(\n",
    "    \"auc ~ income_group_c\",\n",
    "    older_adj_amt_df,\n",
    "    family='beta'\n",
    ")\n",
    "\n",
    "# Display summaries\n",
    "print(\"\\nMCQ Results (Older Adults):\")\n",
    "print(summarize_pymc_model(idata_mcq_income_older, var_names=['Intercept', 'income_group_c']))\n",
    "print(\"\\nAdj-Amt Results (Older Adults):\")\n",
    "print(summarize_pymc_model(idata_adj_amt_income_older, var_names=['Intercept', 'income_group_c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6612168",
   "metadata": {},
   "source": [
    "## 5. Composite Score Analysis\n",
    "\n",
    "The final analyses use the composite z-score—a single, robust measure that combines data from both the MCQ and Adj-Amt procedures—to provide a holistic test of the buffering hypothesis.\n",
    "\n",
    "First, we replicate the focused correlation tests from the paper. As predicted, we expect to find a significant positive correlation between age and financial patience (higher z-score) **only in the low-income group**. Conversely, we expect a significant positive correlation between income and financial patience **only in the younger group**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.1 Focused Correlation Tests with Composite Score ---\n",
    "\n",
    "# Use the composite z-score to perform the two key hypothesis tests in a \n",
    "# single, tidy analysis for each hypothesis.\n",
    "\n",
    "# Test 1: Correlation between Age and Discounting within each Income Group\n",
    "print(\"--- Correlation of Age Group with Discounting z-score ---\")\n",
    "age_correlations = composite_score_df.groupby('income_group').apply(\n",
    "    lambda df: pearsonr(df['mean_z_score'], df['age_group']),\n",
    "    include_groups=False\n",
    ").apply(pd.Series)\n",
    "\n",
    "age_correlations.columns = ['correlation_r', 'p_value']\n",
    "age_correlations.index = age_correlations.index.map({0: 'Low-Income', 1: 'High-Income'})\n",
    "print(age_correlations)\n",
    "\n",
    "\n",
    "# Test 2: Correlation between Income and Discounting within each Age Group\n",
    "print(\"\\n\\n--- Correlation of Income Group with Discounting z-score ---\")\n",
    "income_correlations = composite_score_df.groupby('age_group').apply(\n",
    "    lambda df: pearsonr(df['mean_z_score'], df['income_group']),\n",
    "    include_groups=False\n",
    ").apply(pd.Series)\n",
    "\n",
    "income_correlations.columns = ['correlation_r', 'p_value']\n",
    "income_correlations.index = income_correlations.index.map({0: 'Younger', 1: 'Older'})\n",
    "print(income_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b59527",
   "metadata": {},
   "source": [
    "## 6. Quantifying the Magnitude of the Age Difference\n",
    "\n",
    "Having established the predicted pattern of effects, these final analyses use the composite z-score to quantify the magnitude of the buffering effect. By fitting a series of linear regression models, we can estimate the practical size of the age-related increase in financial patience specifically for the low-income group. This corresponds to the final results presented in the \"Discussion\" section of the publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.1 Group Means and Interaction Model ---\n",
    "\n",
    "# First, calculate and display the mean composite z-score for each of the four\n",
    "# experimental groups to provide context for the regression models.\n",
    "print(\"--- Mean Composite z-Score by Group ---\")\n",
    "mean_z_scores = composite_score_df.groupby(['age_group', 'income_group'])['mean_z_score'].mean().reset_index()\n",
    "mean_z_scores['Age_Group'] = np.where(mean_z_scores['age_group'] == 0, \"Younger\", \"Older\")\n",
    "mean_z_scores['Income_Group'] = np.where(mean_z_scores['income_group'] == 0, \"Low-Income\", \"High-Income\")\n",
    "print(mean_z_scores[['Age_Group', 'Income_Group', 'mean_z_score']])\n",
    "\n",
    "# Next, fit a full linear model with an interaction term. This formally tests\n",
    "# whether the effect of age on discounting depends on a person's income level.\n",
    "print(\"\\n\\n--- Full Model: z_score ~ Age_Group * Income_Group ---\")\n",
    "full_interaction_model = smf.ols(\n",
    "    'mean_z_score ~ age_group_c * income_group_c', \n",
    "    data=composite_score_df\n",
    ").fit()\n",
    "print(full_interaction_model.summary())\n",
    "\n",
    "# --- 6.2 Estimating the Continuous Age Effect by Income Group ---\n",
    "\n",
    "# Finally, model the effect of age as a continuous variable within each\n",
    "# income group separately. This allows us to estimate the year-over-year\n",
    "# change in financial patience (z-score).\n",
    "\n",
    "print(\"\\n\\n--- Continuous Age Effect within Low-Income Group ---\")\n",
    "# As predicted by the buffering hypothesis, we expect a significant, positive slope for age.\n",
    "low_income_age_model = smf.ols(\n",
    "    'mean_z_score ~ Age', \n",
    "    data=composite_score_df[composite_score_df['income_group'] == 0]\n",
    ").fit()\n",
    "print(low_income_age_model.summary())\n",
    "\n",
    "print(\"\\n\\n--- Continuous Age Effect within High-Income Group ---\")\n",
    "# In the high-income group, we expect the slope for age to be non-significant.\n",
    "high_income_age_model = smf.ols(\n",
    "    'mean_z_score ~ Age', \n",
    "    data=composite_score_df[composite_score_df['income_group'] == 1]\n",
    ").fit()\n",
    "print(high_income_age_model.summary())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
